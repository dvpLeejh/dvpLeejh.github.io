---
title: "강화학습을 이용하여 Unity에서 자동차 달리게하기(2/3)"
tags:
  - Machine Learning
  - Project

categories:
    - Machine Learning


date: 2021-08-08
last_modified_at: 2021-08-08

toc: true
toc_sticky: true
---

*** 강화학습 진행하기 ***

# 학습 준비
cmd창의 가상환경(venv)에서
mlagents-learn --help
를 실행했을때 오류없이 실행히 잘됐다면
mlagents-learn
을 실행해도 문제없이 잘 될것이다.
하지만 하이퍼파라미터를 지정하여 원하는 만큼의 훈련횟수와 기타 필요한 옵션들을 설정하고자
yaml파일을 사용한다.

(https://github.com/dvpLeejh/AI-Game-Programming/tree/main/ch06)

yaml파일은 직접 만들수도 있다.
yaml파일을 사용하지않으면 Default값으로 하이퍼파라미터가 지정이되는데
훈련횟수를 늘리고싶다거나, 학습률을 바꾸고 싶다거나, 중간점수체크하는 간격을 변경하고싶거나
할때 yaml파일을 이용한다.

max_steps : 훈련횟수 지정,  여기에서는 천만번을 지정하였다.
summary_freq : 중간 점수 체크 간격이다. 50만번 간격으로 훈련뒤 점수를 출력한다.
checkpoint_interval : 중간중간 모델을 저장하는 간격(체크포인트)다. 50만번 간격으로 저장한다.
그외의 하이퍼파라미터는 어려워서 여기서는 다루지 않는다.

# 보상과 벌점

## 보상
기본적으로 자동차 오브젝트가 체크포인트에 충돌할때마다 보상이 주어진다.
```csharp
public void CheckPointReached(Checkpoint checkpoint){}
```
체크포인트는 기본적으로 순서가 정해져있다.
체크포인트와 접촉했다해도 순서가 맞지 않으면 아무런 보상이 주어지지 않는다.
```csharp
        if (nextCheckPointToReach != checkpoint) 
        {
            return;
        }
```
체크포인트 와접촉했으면 다음 체크포인트를 목표로 변경하고, 보상을 준다.
```csharp
        lastCheckpoint = Checkpoints[CurrentCheckpointIndex];
        reachedCheckpoint?.Invoke(checkpoint);
        CurrentCheckpointIndex++;

        if (CurrentCheckpointIndex >= Checkpoints.Count)
        {
            carAgent.AddReward(1f);
            carAgent.EndEpisode();
        }
        else
        {
            carAgent.checkDirection();
            carAgent.AddReward(1f);
            SetNextCheckpoint();
```
체크포인트를 잘 만들었다면, 자동차는 계속해서 보상을 얻기위해 다음 체크포인트로 갈려 할것이다.

## 벌점
이와 반대로, 자동차가 벽에 충돌하였다면 벌점을 부과한다.
```csharp
    private void OnCollisionEnter(Collision other) {
        if(other.collider.CompareTag("Fence"))
        {
            carAgent.AddReward(-1f);
        }
    } 

    private void OnCollisionStay(Collision other) {
        if(other.collider.CompareTag("Fence"))
        {   
            carAgent.AddReward(-0.5f);
        }
    }
```
벽에 충돌하고도 벽에 붙어있는다면 계속해서 벌점을 받게된다.

결과적으로 자동차는 체크포인트를 향해, 그리고 벽은 피해서 움직이려 하게된다.
이에 대한 정보는 Ray Perception Sensor 3D를 통해 습득이 된다.

# 학습 시작

cmd창을 닫지않았다면 괜찮지만
혹시 닫았다면
cmd창을 다시열어서 아까와같이 activate까지 입력한뒤
가상환경에 접속해야한다.

접속이 완료되면
mlagents-learn "yaml 파일저장위치\파일이름.yaml" --run-id="아무거나"
을 입력한다.

![실행](https://user-images.githubusercontent.com/42956142/128635700-84bdc380-47f2-46e2-8aed-deea86e28aa6.PNG)

이제 준비가 되면 유니티로 돌아가서 실행을 누르면 학습이 시작된다.

![학습중](https://user-images.githubusercontent.com/42956142/128635712-80e26a90-f7a9-4c72-9512-b65971506bc8.PNG)

학습이 완료되면 
프로젝트 폴더\venv\Scripts폴더안에
results폴더가 생성된것을 볼수있다.

그럼 onnx파일이란게 생성되어있는 것을 볼수가 있는데
이것이 바로 우리가 훈련한 모델이다.

그럼 이파일을 적용해보자.

우클릭 -> import New Asset을 통해도 좋고
파일을 직접 유니티에 드래그앤드롭해도 좋다.
아무튼 이파일을 유니티에 넣었으면

자동차의 Behavior Parameters 컴포넌트로 가서
Model에 이 onnx를 드래그앤드롭해주면
모델의 적용이 완료된다.

![onnx](https://user-images.githubusercontent.com/42956142/128635736-f8cf50ee-8a43-4ce1-b93a-91f724996e1b.PNG)

# 결과

tensorboard를 이용해 결과를 확인할수있다.
훈련이 완료되면 cmd창에
```
tensorboard --logdir results --port 6006
```
를 입력하면 된다.

![result1](https://user-images.githubusercontent.com/42956142/128865819-c15f2865-e751-452a-93e2-e8a7b44a711b.PNG)
그러면 주소가 하나 나오게 되는데 이 주소를 복사에서 들어가게 되면

![tensorboard](https://user-images.githubusercontent.com/42956142/128865965-653bb908-60c3-4f89-ae5b-a16fd5f1c1df.PNG)
다음과 같이 그래프로 결과를 확인할 수있다.

기본적으로 훈련횟수가 늘수록 성적도 높아지지만 줄어들때도 있으므로
가장 성적이 높았던 지점에 생성된 모델을 채택하는것도 좋다.
