---
title: "머신러닝을 이용하여 Unity에서 자동차 달리게하기(2/2)"
tags:
  - Machine Learning
  - Project

categories:
    - Machine Learning


date: 2021-08-08
last_modified_at: 2021-08-08

toc: true
toc_sticky: true
---

*** 강화학습 진행하기 ***

# 학습 준비
cmd창의 가상환경(venv)에서
mlagents-learn --help
를 실행했을때 오류없이 실행히 잘됐다면
mlagents-learn
을 실행해도 문제없이 잘 될것이다.
하지만 하이퍼파라미터를 지정하여 원하는 만큼의 훈련횟수와 기타 필요한 옵션들을 설정하고자
yaml파일을 사용한다.

깃헙주소

yaml파일은 직접 만들수도 있다.
yaml파일을 사용하지않으면 Default값으로 하이퍼파라미터가 지정이되는데
훈련횟수를 늘리고싶다거나, 학습률을 바꾸고 싶다거나, 중간점수체크하는 간격을 변경하고싶거나
할때 yaml파일을 이용한다.

max_steps : 훈련횟수 지정,  여기에서는 천만번을 지정하였다.
summary_freq : 중간 점수 체크 간격이다. 50만번 간격으로 훈련뒤 점수를 출력한다.
checkpoint_interval : 중간중간 모델을 저장하는 간격(체크포인트)다. 50만번 간격으로 저장한다.
그외의 하이퍼파라미터는 어려워서 여기서는 다루지 않는다.


# 학습 시작

cmd창을 닫지않았다면 괜찮지만
혹시 닫았다면
cmd창을 다시열어서 아까와같이 activate까지 입력한뒤
가상환경에 접속해야한다.

접속이 완료되면
---
mlagents-learn "yaml 파일저장위치\파일이름.yaml" --run-id="아무거나"
---
을 입력한다.

![실행](https://user-images.githubusercontent.com/42956142/128635700-84bdc380-47f2-46e2-8aed-deea86e28aa6.PNG)

이제 준비가 되면 유니티로 돌아가서 실행을 누르면 학습이 시작된다.

![학습중](https://user-images.githubusercontent.com/42956142/128635712-80e26a90-f7a9-4c72-9512-b65971506bc8.PNG)

학습이 완료되면 
프로젝트 폴더\venv\Scripts폴더안에
results폴더가 생성된것을 볼수있다.

그럼 onnx파일이란게 생성되어있는 것을 볼수가 있는데
이것이 바로 우리가 훈련한 모델이다.

그럼 이파일을 적용해보자.

우클릭 -> import New Asset을 통해도 좋고
파일을 직접 유니티에 드래그앤드롭해도 좋다.
아무튼 이파일을 유니티에 넣었으면

자동차의 Behavior Parameters 컴포넌트로 가서
Model에 이 onnx를 드래그앤드롭해주면
모델의 적용이 완료된다.

![onnx](https://user-images.githubusercontent.com/42956142/128635736-f8cf50ee-8a43-4ce1-b93a-91f724996e1b.PNG)

# 더 빠르게 달리기 위해

마지막으로 더 빨리 체크포인트를 통과했을때
더많은 보상을 준다면
자동차가 과연 얼마나 더빠르게 달릴것인가에 대한 실험을하겠다.

이를위해 코드에
다음과같이 설정을한다.

```csharp
public void CheckPointReached(Checkpoint checkpoint)
{
    //체크포인트
    if (nextCheckPointToReach != checkpoint) 
    {
        return;
    }
    lastCheckpoint = Checkpoints[CurrentCheckpointIndex];
    reachedCheckpoint?.Invoke(checkpoint);
    CurrentCheckpointIndex++;

    if (CurrentCheckpointIndex >= Checkpoints.Count)
    {
        carAgent.AddReward(TimeLeft / 30);         //시간에 대한 보상 추가
        carAgent.AddReward(1f);
        carAgent.EndEpisode();
    }
    else
    {
        carAgent.checkDirection();
        carAgent.AddReward(TimeLeft / 30);     //시간에 대한 보상 추가
        carAgent.AddReward(1f);
        SetNextCheckpoint();
    }
}
```
CheckpointManager스크립트에 가면 위의 코드를 볼수 있다.
체크포인트 구간별로 시간이 30초 주어졌으므로 남은시간 / 30초 로 해서
빠르면 최대 1점의 추가점수를 얻을수 있도록 하였다.

```csharp
public override void CollectObservations(VectorSensor sensor)
{
    Vector3 diff = _checkpointManager.nextCheckPointToReach.transform.position - transform.position;
         
    sensor.AddObservation(diff); // 자동차의 다음체크포인트의 백터좌표 차는 레이케스트가 계산해주는게 아니므로 추가해준다. 
    sensor.AddObservation(_checkpointManager.TimeLeft / 30); // 시간에 대한 보상
    sensor.AddObservation(rb.velocity.magnitude); // 자동차의 속도를 고려하도록 한다.(커브를 위해)

    AddReward(-0.001f); // 자동차가 활발하게 움직이게끔 보상을 조금 줄인다.
}
```
CarAgent스크립트에 가면 위의 코드를 볼수있다.
모델이 남은시간에 대해서 고려할수있게끔 관측을 시킨다.

이후 아까와같이 훈련을 진행한 후 

양쪽의 자동차중 어느것이 더빠른가에 대해 경주를 하였다.
공정한 심사를위해 
Spawnpoint는 하나만 지정하였고, 두개의 자동차에 각각 다른 onnx파일을 적용시켰다.

![차이](https://user-images.githubusercontent.com/42956142/128635867-6939f7f9-ea40-40da-b89a-439c769f4102.PNG)

사진과 같이 시간에 대한 보상이 주어진 모델이
더 빠르게 트랙을 도는것으로 확인된다.
여러번 실행해도 같은 결과를 얻을 수 있었다.

다만 이것은 속도의 문제지 최적화 된 루트로 가느냐 묻는다면
그것은 아니다.

최적화 루트란 예를들어 90도 커브로된 트랙을 지날때
감속을 최소로하기 위해선 
도로 바깥 -> 도로 안-> 도로 바깥의 순서로 지나야
최대한 감속이 적게, 그리고 빠르게 90도 구간을 지날 수있다.
그러나 이와 같은 모습은 보여주지 않았고,
방향은 그대로, 그러나 속도는 최대한 빠르게 지나가는것으로 보였다.ㄴ


